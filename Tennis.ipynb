{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hard_update(target, source):\n",
    "    for target_param, param in zip(target.parameters(), source.parameters()):\n",
    "        target_param.data.copy_(param.data)\n",
    "        \n",
    "def soft_update(target, source, tau):\n",
    "    for target_param, param in zip(target.parameters(), source.parameters()):\n",
    "        target_param.data.copy_(target_param.data * (1.0 - tau) + param.data * tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seeding(seed=10):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OUNoise:\n",
    "    def __init__(self, action_dimension, scale=0.1, mu=0, theta=0.15, sigma=0.2):\n",
    "        self.action_dimension = action_dimension\n",
    "        self.scale = scale\n",
    "        self.mu = mu\n",
    "        self.theta = theta\n",
    "        self.sigma = sigma\n",
    "        self.state = np.ones(self.action_dimension) * self.mu\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = np.ones(self.action_dimension) * self.mu\n",
    "\n",
    "    def noise(self):\n",
    "        x = self.state\n",
    "        dx = self.theta * (self.mu - x) + self.sigma * np.random.randn(len(x))\n",
    "        self.state = x + dx\n",
    "        return torch.tensor(self.state * self.scale).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, buffer_size, batch_size, seed):\n",
    "        self.memory = deque(maxlen=buffer_size)\n",
    "        self.batch_size = batch_size\n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"full_state\", \"action\", \"reward\", \"next_state\", \"full_next_state\", \"done\"])\n",
    "        self.seed = random.seed(seed)\n",
    "\n",
    "    def add(self, state, full_state, action, reward, next_state, full_next_state, done):\n",
    "        e = self.experience(state, full_state, action, reward, next_state, full_next_state, done)\n",
    "        self.memory.append(e)\n",
    "\n",
    "    def sample(self):\n",
    "        experiences = random.sample(self.memory, k=self.batch_size)\n",
    "\n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
    "        full_states = torch.from_numpy(np.vstack([e.full_state for e in experiences if e is not None])).float().to(device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).float().to(device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(\n",
    "            device)\n",
    "        full_next_states = torch.from_numpy(np.vstack([e.full_next_state for e in experiences if e is not None])).float().to(\n",
    "            device)\n",
    "        dones = torch.from_numpy(\n",
    "            np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(\n",
    "            device)\n",
    "\n",
    "        return (states, full_states, actions, rewards, next_states, full_next_states, dones)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hidden_init(layer):\n",
    "    fan_in = layer.weight.data.size()[0]\n",
    "    lim = 1. / np.sqrt(fan_in)\n",
    "    return (-lim, lim)\n",
    "\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, state_size, action_size, seed=1, fc_units=256, fc_units1=128, fc_units2=128):\n",
    "        super(Actor, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_size, fc_units)\n",
    "        self.fc2 = nn.Linear(fc_units, fc_units1)\n",
    "        self.fc3 = nn.Linear(fc_units1, fc_units2)\n",
    "        self.fc4 = nn.Linear(fc_units2, action_size)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.fc1.weight.data.uniform_(*hidden_init(self.fc1))\n",
    "        self.fc2.weight.data.uniform_(*hidden_init(self.fc2))\n",
    "        self.fc3.weight.data.uniform_(*hidden_init(self.fc3))\n",
    "        self.fc4.weight.data.uniform_(-3e-3, 3e-3)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "\n",
    "        return torch.tanh(self.fc4(x))\n",
    "\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, state_size, action_size, num_agent, seed=1, fc_units=256, fc_units1=128, fc_units2=128):\n",
    "        super(Critic, self).__init__()\n",
    "        self.fc1 = nn.Linear((state_size + action_size) * num_agent, fc_units)\n",
    "        self.fc2 = nn.Linear(fc_units, fc_units1)\n",
    "        self.fc3 = nn.Linear(fc_units1, fc_units2)\n",
    "        self.fc4 = nn.Linear(fc_units2, 1)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.fc1.weight.data.uniform_(*hidden_init(self.fc1))\n",
    "        self.fc2.weight.data.uniform_(*hidden_init(self.fc2))\n",
    "        self.fc3.weight.data.uniform_(*hidden_init(self.fc3))\n",
    "        self.fc4.weight.data.uniform_(-3e-3, 3e-3)\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        x = torch.cat((state, action), dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "\n",
    "        return self.fc4(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPGAgent:\n",
    "    def __init__(self, state_size, action_size, num_agents, seed=0, lr_actor=1.0e-4, lr_critic=1.0e-3):\n",
    "        super(DDPGAgent, self).__init__()\n",
    "        \n",
    "        self.actor = Actor(state_size, action_size).to(device)\n",
    "        self.critic = Critic(state_size, action_size, num_agents, seed=seed).to(device)\n",
    "\n",
    "        self.target_actor = Actor(state_size, action_size).to(device)\n",
    "        self.target_critic = Critic(state_size, action_size, num_agents, seed=seed).to(device)\n",
    "\n",
    "        self.noise = OUNoise(action_size, scale=1.0)\n",
    "\n",
    "        hard_update(self.target_actor, self.actor)\n",
    "        hard_update(self.target_critic, self.critic)\n",
    "\n",
    "        self.actor_optimizer = optim.Adam(self.actor.parameters(), lr=lr_actor)\n",
    "        self.critic_optimizer = optim.Adam(self.critic.parameters(), lr=lr_critic)\n",
    "\n",
    "    def act(self, obs, noise=0.0):\n",
    "        obs = obs.to(device)\n",
    "        action = self.actor(obs).cpu().data + noise * self.noise.noise()\n",
    "        return np.clip(action, -1, 1)\n",
    "\n",
    "    def target_act(self, obs, noise=0.0):\n",
    "        obs = obs.to(device)\n",
    "        action = self.target_actor(obs).cpu().data + noise * self.noise.noise()\n",
    "        return np.clip(action, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MADDPG:\n",
    "    def __init__(self, state_size, action_size, num_agents, seed, discount_factor=0.95, tau=0.02):\n",
    "        super(MADDPG, self).__init__()\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.num_agents = num_agents\n",
    "\n",
    "        self.maddpg_agent = [DDPGAgent(state_size, action_size, num_agents, seed),\n",
    "                             DDPGAgent(state_size, action_size, num_agents, seed)]\n",
    "\n",
    "        self.discount_factor = discount_factor\n",
    "        self.tau = tau\n",
    "        self.iter = 0\n",
    "\n",
    "    def get_actors(self):\n",
    "        actors = [ddpg_agent.actor for ddpg_agent in self.maddpg_agent]\n",
    "        return actors\n",
    "\n",
    "    def get_target_actors(self):\n",
    "        target_actors = [ddpg_agent.target_actor for ddpg_agent in self.maddpg_agent]\n",
    "        return target_actors\n",
    "\n",
    "    def act(self, obs_all_agents, noise=0.0):\n",
    "        return [self.maddpg_agent[i].act(obs_all_agents[i, :].view(1, -1), noise).squeeze() for i in range(self.num_agents)]\n",
    "\n",
    "    def target_act(self, obs_all_agents, noise=0.0):\n",
    "        return [self.maddpg_agent[i].target_act(obs_all_agents[:, i, :],  noise).squeeze() for i in range(self.num_agents)] \n",
    "\n",
    "    def update(self, samples, agent_number):\n",
    "        state, full_state, action, reward, next_state, full_next_state, done = samples\n",
    "\n",
    "        batch_size = full_state.shape[0]\n",
    "\n",
    "        agent = self.maddpg_agent[agent_number]\n",
    "        agent.critic_optimizer.zero_grad()\n",
    "\n",
    "        target_actions = self.target_act(next_state.view(batch_size, self.num_agents, -1))\n",
    "\n",
    "        target_actions = torch.cat(target_actions, dim=1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            q_next = agent.target_critic(full_next_state, target_actions.to(device))\n",
    "\n",
    "        y = reward[:, agent_number].view(-1, 1) + self.discount_factor * q_next * (1 - done[:, agent_number].view(-1, 1))\n",
    "\n",
    "        q = agent.critic(full_state, action.view(batch_size, -1))\n",
    "\n",
    "        critic_loss = F.mse_loss(q, y.detach())\n",
    "\n",
    "        critic_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(agent.critic.parameters(), 1)\n",
    "        agent.critic_optimizer.step()\n",
    "\n",
    "        agent.actor_optimizer.zero_grad()\n",
    "\n",
    "        q_input = [\n",
    "            self.maddpg_agent[i].actor(state.view([batch_size, self.num_agents, -1])[:, i, :]) if i == agent_number else\n",
    "            self.maddpg_agent[i].actor(state.view([batch_size, self.num_agents, -1])[:, i, :]).detach() for i in range(self.num_agents)]\n",
    "\n",
    "        q_input = torch.cat(q_input, dim=1)\n",
    "\n",
    "        actor_loss = -agent.critic(full_state, q_input).mean()\n",
    "        actor_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(agent.actor.parameters(), 1)\n",
    "        agent.actor_optimizer.step()\n",
    "\n",
    "        self.update_targets()\n",
    "\n",
    "    def update_targets(self):\n",
    "        \"\"\"soft update targets\"\"\"\n",
    "        self.iter += 1\n",
    "        for ddpg_agent in self.maddpg_agent:\n",
    "            soft_update(ddpg_agent.target_actor, ddpg_agent.actor, self.tau)\n",
    "            soft_update(ddpg_agent.target_critic, ddpg_agent.critic, self.tau)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Number of actions: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like:  [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -6.65278625 -1.5\n",
      " -0.          0.          6.83172083  6.         -0.          0.        ]\n",
      "Episode 0\tAverage Score: 0.0000\tScore: 0.0000\n",
      "Episode 500\tAverage Score: 0.0515\tScore: 0.1000\n",
      "Episode 1000\tAverage Score: 0.1057\tScore: 0.1000\n",
      "Episode 1500\tAverage Score: 0.1005\tScore: 0.1000\n",
      "Episode 2000\tAverage Score: 0.1400\tScore: 0.2000\n",
      "Episode 2500\tAverage Score: 0.1851\tScore: 0.8000\n",
      "Episode 2995\tAverage Score: 0.5049\tScore: 0.9000"
     ]
    }
   ],
   "source": [
    "seeding()\n",
    "\n",
    "env = UnityEnvironment(file_name=\"./Tennis_Windows_x86_64/Tennis.exe\", no_graphics=True)\n",
    "env_name = \"Tennis MADDPG\"\n",
    "\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "\n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like: ', states[0]) \n",
    "\n",
    "num_eps = 10000\n",
    "eps_length = 10000\n",
    "batchsize = 128\n",
    "noise = 1\n",
    "noise_reduction = 0.999\n",
    "\n",
    "model_dir = os.getcwd() + \"/model_dir\"\n",
    "\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "buffer = ReplayBuffer(int(500000), batchsize, 0)\n",
    "\n",
    "maddpg = MADDPG(state_size, action_size, num_agents, seed=10, discount_factor=0.95, tau=0.02)\n",
    "\n",
    "eps_per_update = 2\n",
    "\n",
    "print_every = 500\n",
    "scores_deque = deque(maxlen=100)\n",
    "\n",
    "scores = []\n",
    "avg_100 = []\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "for eps in range(num_eps):\n",
    "    env_info = env.reset(train_mode=True)[brain_name] \n",
    "    state = env_info.vector_observations  \n",
    "    agent0_reward = 0\n",
    "    agent1_reward = 0\n",
    "\n",
    "    for agent in maddpg.maddpg_agent:\n",
    "        agent.noise.reset()\n",
    "\n",
    "    for eps_t in range(eps_length):\n",
    "        actions = maddpg.act(torch.tensor(state, dtype=torch.float), noise=noise)\n",
    "        noise *= noise_reduction\n",
    "\n",
    "        actions_array = torch.stack(actions).detach().numpy()\n",
    "\n",
    "        env_info = env.step(actions_array)[brain_name]\n",
    "        next_state = env_info.vector_observations\n",
    "\n",
    "        reward = env_info.rewards\n",
    "        done = env_info.local_done\n",
    "\n",
    "        agent0_reward += reward[0]\n",
    "        agent1_reward += reward[1]\n",
    "\n",
    "        full_state = np.concatenate((state[0], state[1]))\n",
    "        full_next_state = np.concatenate((next_state[0], next_state[1]))\n",
    "\n",
    "        buffer.add(state, full_state, actions_array, reward, next_state, full_next_state, done)\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "        if len(buffer) > batchsize and eps % eps_per_update == 0:\n",
    "            for i in range(num_agents):\n",
    "                samples = buffer.sample()\n",
    "                maddpg.update(samples, i)\n",
    "            maddpg.update_targets()  \n",
    "\n",
    "        if np.any(done):\n",
    "            break\n",
    "\n",
    "    eps_reward = max(agent0_reward, agent1_reward)\n",
    "    scores.append(eps_reward)\n",
    "    scores_deque.append(eps_reward)\n",
    "    avg_100.append(np.mean(scores_deque))\n",
    "    print('\\rEpisode {}\\tAverage Score: {:.4f}\\tScore: {:.4f}'.format(eps, avg_100[-1],\n",
    "                                                                                    eps_reward),\n",
    "          end=\"\")\n",
    "\n",
    "    if eps % print_every == 0:\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.4f}'.format(eps, avg_100[-1]))\n",
    "\n",
    "    if avg_100[-1] >= threshold:\n",
    "        save_dict_list = []\n",
    "\n",
    "        for i in range(num_agents):\n",
    "            save_dict = {'actor_params': maddpg.maddpg_agent[i].actor.state_dict(),\n",
    "                         'actor_optim_params': maddpg.maddpg_agent[i].actor_optimizer.state_dict(),\n",
    "                         'critic_params': maddpg.maddpg_agent[i].critic.state_dict(),\n",
    "                         'critic_optim_params': maddpg.maddpg_agent[i].critic_optimizer.state_dict()}\n",
    "            save_dict_list.append(save_dict)\n",
    "\n",
    "            torch.save(save_dict_list,\n",
    "                       os.path.join(model_dir, 'episode-{}.pt'.format(eps)))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(0, len(scores))\n",
    "y = np.asarray(avg_100)\n",
    "plt.plot(x, scores)\n",
    "plt.plot(x, y)\n",
    "plt.xlabel(\"Number of Episodes\")\n",
    "plt.legend(['Raw Scores', 'Avg. 100 Scores'], loc='upper left')\n",
    "plt.title(\"Rewards %s\" %env_name)\n",
    "plt.savefig(\"progress.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Number of actions: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like:  [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -6.65278625 -1.5\n",
      " -0.          0.          6.83172083  6.         -0.          0.        ]\n",
      "Episode 0\tAverage Score: 0.1900\tScore: 0.1900\n",
      "Episode 1\tAverage Score: 0.1450\tScore: 0.1000\n",
      "Episode 2\tAverage Score: 0.1633\tScore: 0.2000\n",
      "Episode 3\tAverage Score: 0.1725\tScore: 0.2000\n",
      "Episode 4\tAverage Score: 0.4780\tScore: 1.7000\n",
      "Episode 5\tAverage Score: 0.6983\tScore: 1.8000\n",
      "Episode 6\tAverage Score: 0.9700\tScore: 2.6000\n",
      "Episode 7\tAverage Score: 0.9363\tScore: 0.7000\n",
      "Episode 8\tAverage Score: 0.8544\tScore: 0.2000\n",
      "Episode 9\tAverage Score: 0.7990\tScore: 0.3000\n",
      "Episode 10\tAverage Score: 0.7627\tScore: 0.4000\n",
      "Episode 11\tAverage Score: 0.8575\tScore: 1.9000\n",
      "Episode 12\tAverage Score: 0.8454\tScore: 0.7000\n",
      "Episode 13\tAverage Score: 0.9493\tScore: 2.3000\n",
      "Episode 14\tAverage Score: 0.9187\tScore: 0.4900\n",
      "Episode 15\tAverage Score: 0.9294\tScore: 1.0900\n",
      "Episode 16\tAverage Score: 0.9453\tScore: 1.2000\n",
      "Episode 17\tAverage Score: 0.9039\tScore: 0.2000\n",
      "Episode 18\tAverage Score: 0.9142\tScore: 1.1000\n",
      "Episode 19\tAverage Score: 0.9035\tScore: 0.7000\n",
      "Episode 20\tAverage Score: 0.8795\tScore: 0.4000\n",
      "Episode 21\tAverage Score: 0.9255\tScore: 1.8900\n",
      "Episode 22\tAverage Score: 0.8935\tScore: 0.1900\n",
      "Episode 23\tAverage Score: 0.9604\tScore: 2.5000\n",
      "Episode 24\tAverage Score: 0.9300\tScore: 0.2000\n",
      "Episode 25\tAverage Score: 0.9212\tScore: 0.7000\n",
      "Episode 26\tAverage Score: 0.8981\tScore: 0.3000\n",
      "Episode 27\tAverage Score: 0.9018\tScore: 1.0000\n",
      "Episode 28\tAverage Score: 0.8741\tScore: 0.1000\n",
      "Episode 29\tAverage Score: 0.8483\tScore: 0.1000\n",
      "Episode 30\tAverage Score: 0.8468\tScore: 0.8000\n",
      "Episode 31\tAverage Score: 0.8734\tScore: 1.7000\n",
      "Episode 32\tAverage Score: 0.8894\tScore: 1.4000\n",
      "Episode 33\tAverage Score: 0.8868\tScore: 0.8000\n",
      "Episode 34\tAverage Score: 0.8671\tScore: 0.2000\n",
      "Episode 35\tAverage Score: 0.8681\tScore: 0.9000\n",
      "Episode 36\tAverage Score: 0.8578\tScore: 0.4900\n",
      "Episode 37\tAverage Score: 0.8589\tScore: 0.9000\n",
      "Episode 38\tAverage Score: 0.8469\tScore: 0.3900\n",
      "Episode 39\tAverage Score: 0.8358\tScore: 0.4000\n",
      "Episode 40\tAverage Score: 0.8276\tScore: 0.5000\n",
      "Episode 41\tAverage Score: 0.8698\tScore: 2.6000\n",
      "Episode 42\tAverage Score: 0.8681\tScore: 0.8000\n",
      "Episode 43\tAverage Score: 0.9075\tScore: 2.6000\n",
      "Episode 44\tAverage Score: 0.8896\tScore: 0.1000\n",
      "Episode 45\tAverage Score: 0.8811\tScore: 0.5000\n",
      "Episode 46\tAverage Score: 0.8685\tScore: 0.2900\n",
      "Episode 47\tAverage Score: 0.8775\tScore: 1.3000\n",
      "Episode 48\tAverage Score: 0.8739\tScore: 0.7000\n",
      "Episode 49\tAverage Score: 0.8964\tScore: 2.0000\n",
      "Episode 50\tAverage Score: 0.8906\tScore: 0.6000\n",
      "Episode 51\tAverage Score: 0.9081\tScore: 1.8000\n",
      "Episode 52\tAverage Score: 0.9004\tScore: 0.5000\n",
      "Episode 53\tAverage Score: 0.8930\tScore: 0.5000\n",
      "Episode 54\tAverage Score: 0.8804\tScore: 0.2000\n",
      "Episode 55\tAverage Score: 0.8664\tScore: 0.1000\n",
      "Episode 56\tAverage Score: 0.8723\tScore: 1.2000\n",
      "Episode 57\tAverage Score: 0.8641\tScore: 0.4000\n",
      "Episode 58\tAverage Score: 0.8681\tScore: 1.1000\n",
      "Episode 59\tAverage Score: 0.8720\tScore: 1.1000\n",
      "Episode 60\tAverage Score: 0.8610\tScore: 0.2000\n",
      "Episode 61\tAverage Score: 0.8487\tScore: 0.1000\n",
      "Episode 62\tAverage Score: 0.8400\tScore: 0.3000\n",
      "Episode 63\tAverage Score: 0.8595\tScore: 2.0900\n",
      "Episode 64\tAverage Score: 0.8632\tScore: 1.1000\n",
      "Episode 65\tAverage Score: 0.8606\tScore: 0.6900\n",
      "Episode 66\tAverage Score: 0.8537\tScore: 0.4000\n",
      "Episode 67\tAverage Score: 0.8500\tScore: 0.6000\n",
      "Episode 68\tAverage Score: 0.8754\tScore: 2.6000\n",
      "Episode 69\tAverage Score: 0.8843\tScore: 1.5000\n",
      "Episode 70\tAverage Score: 0.8803\tScore: 0.6000\n",
      "Episode 71\tAverage Score: 0.8722\tScore: 0.3000\n",
      "Episode 72\tAverage Score: 0.8685\tScore: 0.6000\n",
      "Episode 73\tAverage Score: 0.8824\tScore: 1.9000\n",
      "Episode 74\tAverage Score: 0.8800\tScore: 0.7000\n",
      "Episode 75\tAverage Score: 0.8711\tScore: 0.2000\n",
      "Episode 76\tAverage Score: 0.8661\tScore: 0.4900\n",
      "Episode 77\tAverage Score: 0.8653\tScore: 0.8000\n",
      "Episode 78\tAverage Score: 0.8594\tScore: 0.4000\n",
      "Episode 79\tAverage Score: 0.8636\tScore: 1.2000\n",
      "Episode 80\tAverage Score: 0.8851\tScore: 2.6000\n",
      "Episode 81\tAverage Score: 0.8743\tScore: 0.0000\n",
      "Episode 82\tAverage Score: 0.8758\tScore: 1.0000\n",
      "Episode 83\tAverage Score: 0.8689\tScore: 0.3000\n",
      "Episode 84\tAverage Score: 0.8609\tScore: 0.1900\n",
      "Episode 85\tAverage Score: 0.8660\tScore: 1.3000\n",
      "Episode 86\tAverage Score: 0.8595\tScore: 0.3000\n",
      "Episode 87\tAverage Score: 0.8555\tScore: 0.5000\n",
      "Episode 88\tAverage Score: 0.8536\tScore: 0.6900\n",
      "Episode 89\tAverage Score: 0.8608\tScore: 1.5000\n",
      "Episode 90\tAverage Score: 0.8545\tScore: 0.2900\n",
      "Episode 91\tAverage Score: 0.8615\tScore: 1.5000\n",
      "Episode 92\tAverage Score: 0.8652\tScore: 1.2000\n",
      "Episode 93\tAverage Score: 0.8570\tScore: 0.1000\n",
      "Episode 94\tAverage Score: 0.8585\tScore: 1.0000\n",
      "Episode 95\tAverage Score: 0.8548\tScore: 0.5000\n",
      "Episode 96\tAverage Score: 0.8563\tScore: 1.0000\n",
      "Episode 97\tAverage Score: 0.8486\tScore: 0.1000\n",
      "Episode 98\tAverage Score: 0.8511\tScore: 1.1000\n",
      "Episode 99\tAverage Score: 0.8596\tScore: 1.7000\n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"./Tennis_Windows_x86_64/Tennis.exe\", no_graphics=True)\n",
    "\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "\n",
    "env_info = env.reset(train_mode=False)[brain_name]\n",
    "\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "\n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like: ', states[0]) \n",
    "\n",
    "num_eps = 100\n",
    "eps_length = 10000\n",
    "\n",
    "scores_deque = deque(maxlen=100)\n",
    "\n",
    "scores = []\n",
    "avg_100 = []\n",
    "\n",
    "for eps in range(num_eps):\n",
    "    env_info = env.reset(train_mode=True)[brain_name] \n",
    "    state = env_info.vector_observations  \n",
    "    agent0_reward = 0\n",
    "    agent1_reward = 0\n",
    "\n",
    "    for eps_t in range(eps_length):\n",
    "        actions = maddpg.act(torch.tensor(state, dtype=torch.float), noise=0)\n",
    "\n",
    "        actions_array = torch.stack(actions).detach().numpy()\n",
    "\n",
    "        env_info = env.step(actions_array)[brain_name]\n",
    "        next_state = env_info.vector_observations\n",
    "\n",
    "        reward = env_info.rewards\n",
    "        done = env_info.local_done\n",
    "\n",
    "        agent0_reward += reward[0]\n",
    "        agent1_reward += reward[1]\n",
    "\n",
    "        state = next_state\n",
    "        if np.any(done):\n",
    "            break\n",
    "\n",
    "    eps_reward = max(agent0_reward, agent1_reward)\n",
    "    scores.append(eps_reward)\n",
    "    scores_deque.append(eps_reward)\n",
    "    avg_100.append(np.mean(scores_deque))\n",
    "    print('Episode {}\\tAverage Score: {:.4f}\\tScore: {:.4f}\\n'.format(eps, avg_100[-1], eps_reward),end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
